{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Ya ML CV HW 6"
      ],
      "metadata": {
        "id": "Juk8p2yT6xbd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# загрузили архив https://disk.yandex.ru/d/ECLHqVyX-F5hRA\n",
        "!mkdir -p my_folder\n",
        "!tar -xvzf best_pictures.tar.gz -C my_folder"
      ],
      "metadata": {
        "id": "UVZCOsNw9U-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Считываем\n",
        "filters_df = pd.read_csv('my_folder/algos.csv', header=None)\n",
        "\n",
        "# Превращаем строки в 3×3 фильтры\n",
        "filter1 = filters_df.iloc[0].values.reshape((3, 3))\n",
        "filter2 = filters_df.iloc[1].values.reshape((3, 3))\n",
        "\n",
        "print(\"Фильтр 1:\\n\", filter1)\n",
        "print(\"Фильтр 2:\\n\", filter2)\n"
      ],
      "metadata": {
        "id": "kPUMeS_0_-eY",
        "outputId": "b9a49c50-0e49-4f33-b314-7bf8c0a57dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Фильтр 1:\n",
            " [[-1.  -0.5  0. ]\n",
            " [-0.5  0.5  0.5]\n",
            " [ 0.   0.5  1. ]]\n",
            "Фильтр 2:\n",
            " [[0.0625 0.0625 0.0625]\n",
            " [0.0625 0.0625 0.0625]\n",
            " [0.0625 0.0625 0.0625]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Третий фильтр, например, размытие (усреднение)\n",
        "filter3 = np.array([[1,1,1],\n",
        "                    [1,1,1],\n",
        "                    [1,1,1]]) / 9\n"
      ],
      "metadata": {
        "id": "cXAQOxZlCiaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.ndimage import convolve\n",
        "from PIL import Image\n",
        "\n",
        "# Загружаем изображение в ч/б\n",
        "img = Image.open('my_folder/1.png').convert('L')\n",
        "img_array = np.array(img)\n",
        "\n",
        "# Применяем фильтры по очереди\n",
        "out1 = convolve(img_array, filter1, mode='reflect')\n",
        "out2 = convolve(out1, filter2, mode='reflect')\n",
        "out3 = convolve(out2, filter3, mode='reflect')\n",
        "\n",
        "# Сохраним результат чтобы посмотреть\n",
        "Image.fromarray(np.clip(out3, 0, 255).astype(np.uint8)).save('output.png')\n"
      ],
      "metadata": {
        "id": "QA2Qp5l2Ck1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Читаем эталон из txt\n",
        "ref = np.loadtxt('my_folder/1.txt')\n",
        "\n",
        "# Сравниваем\n",
        "difference = np.abs(ref - out3)\n",
        "print(\"Средняя ошибка:\", np.mean(difference))\n",
        "print(\"Максимальная ошибка:\", np.max(difference))\n"
      ],
      "metadata": {
        "id": "aRXxH5vwCtuF",
        "outputId": "b32345fc-5e77-4e2a-b6f9-68cfb21d0f88",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Средняя ошибка: 47.871323585510254\n",
            "Максимальная ошибка: 342.44921875\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import numpy as np\n",
        "from scipy.ndimage import convolve\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Загружаем фильтры из CSV\n",
        "filters_df = pd.read_csv('my_folder/algos.csv', header=None)\n",
        "filter1 = filters_df.iloc[0].values.reshape((3, 3))\n",
        "filter2 = filters_df.iloc[1].values.reshape((3, 3))\n",
        "\n",
        "# 2. Загружаем картинку и эталон\n",
        "img = Image.open('my_folder/1.png').convert('L')\n",
        "img_array = np.array(img)\n",
        "\n",
        "ref = np.loadtxt('my_folder/1.txt')\n",
        "\n",
        "# 3. Функция для теста комбинации фильтров\n",
        "def test_filters(filters, order, img_array, ref):\n",
        "    temp = img_array.copy()\n",
        "    for idx in order:\n",
        "        temp = convolve(temp, filters[idx], mode='reflect')\n",
        "    difference = np.abs(ref - temp)\n",
        "    mean_error = np.mean(difference)\n",
        "    return mean_error, temp\n",
        "\n",
        "# 4. Автоматический перебор\n",
        "best_error = float('inf')\n",
        "best_order = None\n",
        "best_filter3 = None\n",
        "best_output = None\n",
        "\n",
        "# Генерируем разные варианты третьего фильтра\n",
        "# (можно сделать более умную генерацию позже)\n",
        "possible_values = [-1, 0, 1, 2]  # значения для ячеек фильтра\n",
        "all_possible_filters3 = []\n",
        "\n",
        "for vals in itertools.product(possible_values, repeat=9):\n",
        "    f3 = np.array(vals).reshape((3, 3))\n",
        "    all_possible_filters3.append(f3)\n",
        "\n",
        "print(f\"Всего вариантов третьего фильтра: {len(all_possible_filters3)}\")\n",
        "\n",
        "# Перебираем все варианты\n",
        "for f3 in all_possible_filters3:\n",
        "    filters = [filter1, filter2, f3]\n",
        "\n",
        "    for order in itertools.permutations([0, 1, 2]):\n",
        "        mean_error, temp = test_filters(filters, order, img_array, ref)\n",
        "\n",
        "        if mean_error < best_error:\n",
        "            best_error = mean_error\n",
        "            best_order = order\n",
        "            best_filter3 = f3.copy()\n",
        "            best_output = temp.copy()\n",
        "\n",
        "print(\"\\n=== Результаты ===\")\n",
        "print(\"Лучшая ошибка:\", best_error)\n",
        "print(\"Лучший порядок фильтров:\", best_order)\n",
        "print(\"Лучший третий фильтр:\\n\", best_filter3)\n",
        "\n",
        "# Сохраняем лучший результат\n",
        "Image.fromarray(np.clip(best_output, 0, 255).astype(np.uint8)).save('best_output.png')\n"
      ],
      "metadata": {
        "id": "UaF0Kja1DRV2",
        "outputId": "83b276f1-5871-4873-abe3-ffb95ec70801",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего вариантов третьего фильтра: 262144\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-2559803d4dd4>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mmean_error\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_filters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmean_error\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mbest_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-2559803d4dd4>\u001b[0m in \u001b[0;36mtest_filters\u001b[0;34m(filters, order, img_array, ref)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_array\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'reflect'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mdifference\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mmean_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdifference\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/ndimage/_filters.py\u001b[0m in \u001b[0;36mconvolve\u001b[0;34m(input, weights, output, mode, cval, origin)\u001b[0m\n\u001b[1;32m    973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    974\u001b[0m     \"\"\"\n\u001b[0;32m--> 975\u001b[0;31m     return _correlate_or_convolve(input, weights, output, mode, cval,\n\u001b[0m\u001b[1;32m    976\u001b[0m                                   origin, True)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/ndimage/_filters.py\u001b[0m in \u001b[0;36m_correlate_or_convolve\u001b[0;34m(input, weights, output, mode, cval, origin, convolution)\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"A sequence of modes is not supported\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ni_support\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_mode_to_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 797\u001b[0;31m     \u001b[0m_nd_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorrelate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morigins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    798\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtemp_needed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0mtemp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# НЕЙРОНКОЙ ПОДБЕРЕМ ФИЛЬТР\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "\n",
        "# Загружаем фильтры из CSV\n",
        "filters_df = pd.read_csv('my_folder/algos.csv', header=None)\n",
        "filter1 = torch.tensor(filters_df.iloc[0].values.reshape((3, 3)), dtype=torch.float32)\n",
        "filter2 = torch.tensor(filters_df.iloc[1].values.reshape((3, 3)), dtype=torch.float32)\n",
        "\n",
        "# Фиксированные фильтры для свёртки\n",
        "fixed_filters = [filter2, filter1]\n",
        "\n",
        "# Собираем все файлы в папке\n",
        "image_files = sorted(glob.glob('my_folder/*.png'))\n",
        "txt_files = sorted(glob.glob('my_folder/*.txt'))\n",
        "\n",
        "dataset = []\n",
        "for img_path, txt_path in zip(image_files, txt_files):\n",
        "    img = Image.open(img_path).convert('L')\n",
        "    img_array = np.array(img, dtype=np.float32) #/ 255.0  # нормализация\n",
        "    target_array = np.loadtxt(txt_path).astype(np.float32) #/ 255.0  # нормализация\n",
        "\n",
        "    dataset.append((torch.tensor(img_array).unsqueeze(0), torch.tensor(target_array).unsqueeze(0)))  # (1, H, W)\n",
        "\n",
        "class LearnableFilter(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # Инициализируем третий фильтр случайными числами\n",
        "        self.learned_filter = nn.Parameter(torch.randn(1, 1, 3, 3))  # 1 входной канал, 1 выходной канал, 3x3\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Применяем фиксированные фильтры (ручная свёртка)\n",
        "        for filt in fixed_filters[1:]:\n",
        "            filt = filt.unsqueeze(0).unsqueeze(0)  # (out_channels, in_channels, H, W)\n",
        "            x = nn.functional.conv2d(x, filt, padding=1)\n",
        "\n",
        "        # Применяем обучаемый фильтр\n",
        "        x = nn.functional.conv2d(x, self.learned_filter, padding=1)\n",
        "\n",
        "        # Применяем фиксированные фильтры (ручная свёртка)\n",
        "        for filt in fixed_filters[:1]:\n",
        "            filt = filt.unsqueeze(0).unsqueeze(0)  # (out_channels, in_channels, H, W)\n",
        "            x = nn.functional.conv2d(x, filt, padding=1)\n",
        "\n",
        "        return x\n",
        "\n",
        "model = LearnableFilter()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "n_epochs = 100\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    total_loss = 0.0\n",
        "    for img_tensor, target_tensor in dataset:\n",
        "        img_tensor = img_tensor.unsqueeze(0)  # добавляем batch размерность\n",
        "        target_tensor = target_tensor.unsqueeze(0)\n",
        "\n",
        "        output = model(img_tensor)\n",
        "        loss = loss_fn(output, target_tensor)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    if (epoch+1) % 1 == 0 or epoch == 0:\n",
        "        print(f\"Эпоха {epoch+1}, Loss: {total_loss/len(dataset)}\")\n",
        "\n",
        "print(\"\\nОбучение завершено!\")\n",
        "print(\"Обученный третий фильтр:\")\n",
        "print(model.learned_filter.detach().squeeze().numpy())"
      ],
      "metadata": {
        "id": "L6Wwf5HfEtcJ",
        "outputId": "3822d0fc-1703-4c2b-8bf5-3e208b9d8b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 981
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Эпоха 1, Loss: 1254.842674058914\n",
            "Эпоха 2, Loss: 952.0612042121887\n",
            "Эпоха 3, Loss: 936.7474290885925\n",
            "Эпоха 4, Loss: 930.0377954788208\n",
            "Эпоха 5, Loss: 927.0875525684356\n",
            "Эпоха 6, Loss: 925.5423328304291\n",
            "Эпоха 7, Loss: 924.5120725803375\n",
            "Эпоха 8, Loss: 923.6857079887391\n",
            "Эпоха 9, Loss: 922.9555663642883\n",
            "Эпоха 10, Loss: 922.2834357376098\n",
            "Эпоха 11, Loss: 921.6548242835999\n",
            "Эпоха 12, Loss: 921.0633903121948\n",
            "Эпоха 13, Loss: 920.5056728458404\n",
            "Эпоха 14, Loss: 919.9793096599578\n",
            "Эпоха 15, Loss: 919.4823542613983\n",
            "Эпоха 16, Loss: 919.0131056175231\n",
            "Эпоха 17, Loss: 918.5700126514434\n",
            "Эпоха 18, Loss: 918.1515630645752\n",
            "Эпоха 19, Loss: 917.7564108867646\n",
            "Эпоха 20, Loss: 917.3832849788665\n",
            "Эпоха 21, Loss: 917.030924150467\n",
            "Эпоха 22, Loss: 916.6981822738647\n",
            "Эпоха 23, Loss: 916.3839755363464\n",
            "Эпоха 24, Loss: 916.0872711715698\n",
            "Эпоха 25, Loss: 915.8071054039001\n",
            "Эпоха 26, Loss: 915.5425574855805\n",
            "Эпоха 27, Loss: 915.292736995697\n",
            "Эпоха 28, Loss: 915.0568533267975\n",
            "Эпоха 29, Loss: 914.8341176395417\n",
            "Эпоха 30, Loss: 914.6238038463592\n",
            "Эпоха 31, Loss: 914.4252179489135\n",
            "Эпоха 32, Loss: 914.2377189292907\n",
            "Эпоха 33, Loss: 914.0606673107147\n",
            "Эпоха 34, Loss: 913.8935093326569\n",
            "Эпоха 35, Loss: 913.7356674499512\n",
            "Эпоха 36, Loss: 913.5866336116791\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-bef6060845fe>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    624\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             )\n\u001b[0;32m--> 626\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    824\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import glob\n",
        "\n",
        "def evaluate_model(model, image_folder='my_folder'):\n",
        "    image_files = sorted(glob.glob(f'{image_folder}/*.png'))\n",
        "    txt_files = sorted(glob.glob(f'{image_folder}/*.txt'))\n",
        "\n",
        "    mse_losses = []\n",
        "\n",
        "    for img_path, txt_path in zip(image_files, txt_files):\n",
        "        # Загрузка изображения (без нормализации!)\n",
        "        img = Image.open(img_path).convert('L')\n",
        "        img_tensor = torch.tensor(np.array(img, dtype=np.float32)).unsqueeze(0).unsqueeze(0)  # (B, C, H, W)\n",
        "\n",
        "        # Загрузка целевого выхода\n",
        "        target_array = np.loadtxt(txt_path).astype(np.float32)\n",
        "        target_tensor = torch.tensor(target_array).unsqueeze(0).unsqueeze(0)  # (B, C, H, W)\n",
        "\n",
        "        # Прогон через модель\n",
        "        output = model(img_tensor)\n",
        "\n",
        "        # Подсчёт MSE для этой пары\n",
        "        mse = F.mse_loss(output, target_tensor).item()\n",
        "        mse_losses.append(mse)\n",
        "\n",
        "    # Среднее значение MSE\n",
        "    avg_mse = np.mean(mse_losses)\n",
        "    print(f\"Среднее MSE на всех данных: {avg_mse:.6f}\")\n",
        "    return avg_mse\n",
        "\n",
        "evaluate_model(model)"
      ],
      "metadata": {
        "id": "I1pEI3qDMT1c",
        "outputId": "e29d598f-3040-4037-e38e-e1782f2704ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Среднее MSE на всех данных: 0.000000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(6.252211647329864e-10)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Готовим всё для отправки\n",
        "\n",
        "# 1. Фиксированные фильтры\n",
        "filter1 = filters_df.iloc[0].values.reshape((3, 3))\n",
        "filter2 = filters_df.iloc[1].values.reshape((3, 3))\n",
        "\n",
        "# 2. Обученный фильтр\n",
        "learned_filter = model.learned_filter.detach().squeeze().numpy()\n",
        "\n",
        "# 3. Собираем всё в одну кучу\n",
        "all_filters = [filter1, filter2, learned_filter]\n",
        "\n",
        "# 4. Готовим строки для отправки\n",
        "rows = []\n",
        "for f in all_filters:\n",
        "    row = ','.join([f\"{x:.4f}\" for x in f.flatten()])\n",
        "    rows.append(row)\n",
        "\n",
        "# 5. Объединяем\n",
        "submission = '\\n'.join(rows)\n",
        "\n",
        "print(submission)"
      ],
      "metadata": {
        "id": "kTf1UvB5KcMH",
        "outputId": "fff345d8-5be5-44c7-a55f-446d232feefb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-1.0000,-0.5000,0.0000,-0.5000,0.5000,0.5000,0.0000,0.5000,1.0000\n",
            "0.0625,0.0625,0.0625,0.0625,0.0625,0.0625,0.0625,0.0625,0.0625\n",
            "0.1250,0.2500,0.1250,0.2500,0.5000,0.2500,0.1250,0.2500,0.1250\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1 2 3\n",
        "Loss: 889.9\n",
        "\n",
        "2 1 3\n",
        "Loss: 43.8\n",
        "\n",
        "3 1 2\n",
        "Loss: 515.0\n",
        "\n",
        "3 2 1\n",
        "Loss: 4.5137745437906496e-07\n",
        "\n",
        "1 3 2\n",
        "Loss: 1.417360968758441e-09\n",
        "\n",
        "2 3 1\n",
        "Loss: 913.5866336116791"
      ],
      "metadata": {
        "id": "kSU2chsRN0hL"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}